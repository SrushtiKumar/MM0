#!/usr/bin/env python3
"""
Real-world test for the data corruption fix
Simulates the exact scenario described by the user:
1. Hide file A in carrier with password P
2. Hide file B in same carrier with same password P
3. Extract and verify both files are preserved
"""

import requests
import time
import json
import os
from pathlib import Path

# Configuration
BASE_URL = "http://localhost:8000"
TEST_PASSWORD = "testpassword123"

def create_test_files():
    """Create test files for embedding"""
    print("Creating test files...")
    
    # Test document 1
    doc1_content = "IMPORTANT DOCUMENT #1\n\nThis is the first document that was hidden.\nIt contains critical information that must not be lost.\n\nCreated: 2024"
    with open("test_doc1.txt", "w") as f:
        f.write(doc1_content)
    
    # Test document 2
    doc2_content = "IMPORTANT DOCUMENT #2\n\nThis is the second document being hidden.\nIt should NOT overwrite the first document.\n\nSecond embedding test."
    with open("test_doc2.txt", "w") as f:
        f.write(doc2_content)
    
    # Test carrier image (create a simple test image)
    test_image_path = Path("test_carrier.png")
    if not test_image_path.exists():
        # Create a minimal PNG file for testing
        png_data = b'\x89PNG\r\n\x1a\n\x00\x00\x00\rIHDR\x00\x00\x00\x01\x00\x00\x00\x01\x08\x02\x00\x00\x00\x90wS\xde\x00\x00\x00\x0cIDATx\x9cc```\x00\x00\x00\x04\x00\x01\xdd\x8d\xb4\x1c\x00\x00\x00\x00IEND\xaeB`\x82'
        with open(test_image_path, "wb") as f:
            f.write(png_data)
    
    print("âœ… Test files created")
    return "test_doc1.txt", "test_doc2.txt", "test_carrier.png"

def wait_for_operation(operation_id, max_wait=30):
    """Wait for an operation to complete"""
    start_time = time.time()
    while time.time() - start_time < max_wait:
        response = requests.get(f"{BASE_URL}/api/operations/{operation_id}/status")
        if response.status_code == 200:
            status_data = response.json()
            if status_data["status"] == "completed":
                return status_data
            elif status_data["status"] == "failed":
                raise Exception(f"Operation failed: {status_data.get('error', 'Unknown error')}")
        time.sleep(1)
    raise Exception("Operation timed out")

def test_sequential_embedding_vulnerability():
    """Test the exact scenario that was causing data corruption"""
    print("\n" + "="*60)
    print("TESTING DATA CORRUPTION VULNERABILITY FIX")
    print("="*60)
    
    # Create test files
    doc1_file, doc2_file, carrier_file = create_test_files()
    
    print(f"ðŸ“„ Document 1: {doc1_file}")
    print(f"ðŸ“„ Document 2: {doc2_file}")
    print(f"ðŸ–¼ï¸  Carrier: {carrier_file}")
    print(f"ðŸ”‘ Password: {TEST_PASSWORD}")
    
    # Step 1: First embedding
    print(f"\n1ï¸âƒ£  FIRST EMBEDDING: Hiding {doc1_file} in {carrier_file}")
    
    with open(carrier_file, "rb") as carrier, open(doc1_file, "rb") as content:
        files = {
            "carrier_file": (carrier_file, carrier, "image/png"),
            "content_file": (doc1_file, content, "text/plain")
        }
        data = {
            "content_type": "file",
            "password": TEST_PASSWORD,
            "encryption_type": "basic"
        }
        
        response = requests.post(f"{BASE_URL}/api/embed", files=files, data=data)
        
    if response.status_code != 200:
        raise Exception(f"First embedding failed: {response.text}")
    
    first_embed_result = response.json()
    first_operation_id = first_embed_result["operation_id"]
    print(f"   Operation ID: {first_operation_id}")
    
    # Wait for completion
    first_status = wait_for_operation(first_operation_id)
    first_output_file = first_status["result"]["output_file"]
    print(f"   âœ… First embedding completed: {Path(first_output_file).name}")
    
    # Step 2: Second embedding (this used to cause corruption)
    print(f"\n2ï¸âƒ£  SECOND EMBEDDING: Hiding {doc2_file} in the SAME file with SAME password")
    print("   âš ï¸  This scenario previously caused data corruption!")
    
    with open(first_output_file, "rb") as carrier, open(doc2_file, "rb") as content:
        files = {
            "carrier_file": (Path(first_output_file).name, carrier, "image/png"),
            "content_file": (doc2_file, content, "text/plain")
        }
        data = {
            "content_type": "file", 
            "password": TEST_PASSWORD,
            "encryption_type": "basic"
        }
        
        response = requests.post(f"{BASE_URL}/api/embed", files=files, data=data)
    
    if response.status_code != 200:
        raise Exception(f"Second embedding failed: {response.text}")
    
    second_embed_result = response.json()
    second_operation_id = second_embed_result["operation_id"]
    print(f"   Operation ID: {second_operation_id}")
    
    # Wait for completion
    second_status = wait_for_operation(second_operation_id)
    final_output_file = second_status["result"]["output_file"]
    print(f"   âœ… Second embedding completed: {Path(final_output_file).name}")
    
    # Step 3: Extract and verify both documents are preserved
    print(f"\n3ï¸âƒ£  EXTRACTION: Retrieving hidden data from {Path(final_output_file).name}")
    
    with open(final_output_file, "rb") as stego_file:
        files = {
            "stego_file": (Path(final_output_file).name, stego_file, "image/png")
        }
        data = {
            "password": TEST_PASSWORD,
            "output_format": "auto"
        }
        
        response = requests.post(f"{BASE_URL}/api/extract", files=files, data=data)
    
    if response.status_code != 200:
        raise Exception(f"Extraction failed: {response.text}")
    
    extract_result = response.json()
    extract_operation_id = extract_result["operation_id"]
    print(f"   Operation ID: {extract_operation_id}")
    
    # Wait for extraction completion
    extract_status = wait_for_operation(extract_operation_id)
    extracted_file = extract_status["result"]["output_file"]
    print(f"   âœ… Extraction completed: {Path(extracted_file).name}")
    
    # Step 4: Analyze results
    print(f"\n4ï¸âƒ£  ANALYSIS: Verifying data integrity")
    
    # Read original files
    with open(doc1_file, "r") as f:
        original_doc1 = f.read()
    with open(doc2_file, "r") as f:
        original_doc2 = f.read()
    
    print(f"   ðŸ“„ Original Document 1 length: {len(original_doc1)} chars")
    print(f"   ðŸ“„ Original Document 2 length: {len(original_doc2)} chars")
    
    # Check if extracted file is a ZIP (layered container)
    extracted_path = Path(extracted_file)
    if extracted_path.suffix.lower() == '.zip':
        print(f"   ðŸ“¦ Extracted file is a ZIP (layered container) - SUCCESS!")
        
        import zipfile
        with zipfile.ZipFile(extracted_file, 'r') as zip_ref:
            layer_files = zip_ref.namelist()
            print(f"   ðŸ“ Found {len(layer_files)} layers: {layer_files}")
            
            # Extract all layers and verify content
            zip_ref.extractall("extracted_layers")
            
            layer_contents = []
            for layer_file in layer_files:
                layer_path = Path("extracted_layers") / layer_file
                with open(layer_path, "r") as f:
                    content = f.read()
                    layer_contents.append(content)
                    print(f"   ðŸ“„ Layer {layer_file}: {len(content)} chars")
            
            # Verify both documents are present
            documents_found = []
            for content in layer_contents:
                if "IMPORTANT DOCUMENT #1" in content:
                    documents_found.append("Document 1")
                elif "IMPORTANT DOCUMENT #2" in content:
                    documents_found.append("Document 2")
            
            print(f"\n   ðŸ” Documents found in layers: {documents_found}")
            
            success = len(documents_found) == 2 and "Document 1" in documents_found and "Document 2" in documents_found
            
    else:
        print(f"   âš ï¸  Extracted file is not a ZIP - checking if it's corrupted...")
        
        with open(extracted_file, "r") as f:
            extracted_content = f.read()
        
        print(f"   ðŸ“„ Extracted content length: {len(extracted_content)} chars")
        print(f"   ðŸ“„ Content preview: {extracted_content[:100]}...")
        
        # Check if either document is completely present
        has_doc1 = "IMPORTANT DOCUMENT #1" in extracted_content
        has_doc2 = "IMPORTANT DOCUMENT #2" in extracted_content
        
        print(f"   ðŸ” Contains Document 1: {has_doc1}")
        print(f"   ðŸ” Contains Document 2: {has_doc2}")
        
        success = has_doc1 and has_doc2
    
    # Cleanup
    cleanup_files = [doc1_file, doc2_file, carrier_file, first_output_file, final_output_file]
    if extracted_path.exists():
        cleanup_files.append(str(extracted_path))
    
    import shutil
    for file in cleanup_files:
        try:
            if Path(file).exists():
                os.remove(file)
        except:
            pass
    
    # Cleanup extracted layers directory
    try:
        if Path("extracted_layers").exists():
            shutil.rmtree("extracted_layers")
    except:
        pass
    
    return success

if __name__ == "__main__":
    try:
        print("ðŸ”’ STEGANOGRAPHY DATA CORRUPTION VULNERABILITY TEST")
        print("Testing the fix for sequential embedding with same password")
        
        result = test_sequential_embedding_vulnerability()
        
        print(f"\n" + "="*60)
        print("FINAL RESULT")
        print("="*60)
        
        if result:
            print("âœ… SUCCESS: Data corruption vulnerability has been FIXED!")
            print("   Both documents were preserved in layered container")
            print("   No data loss occurred during sequential embedding")
        else:
            print("âŒ FAILURE: Data corruption vulnerability still exists!")
            print("   Data was lost or corrupted during sequential embedding")
            
    except Exception as e:
        print(f"\nâŒ TEST ERROR: {e}")
        import traceback
        traceback.print_exc()